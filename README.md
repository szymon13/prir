# Przetwarzanie rÃ³wnolegÅ‚e i rozproszone projetk
Ciesielski Syzmon 21223
BÅ‚aÅ¼ko Jakub 21215

# ğŸ•·ï¸ Web Scraper App

**Web Scraper App** to rozproszona aplikacja sÅ‚uÅ¼Ä…ca do automatycznego pobierania i selekcji danych z witryn internetowych wedÅ‚ug zdefiniowanego profilu. Projekt wspiera przetwarzanie rÃ³wnolegÅ‚e, parsowanie z uÅ¼yciem BeautifulSoup oraz zapis danych do MongoDB. Aplikacja skÅ‚ada siÄ™ z moduÅ‚u silnika (`engine`) oraz interfejsu webowego (`web`).

---

## ğŸ“ Struktura projektu

web-scraper-app/
â”œâ”€â”€ engine/ # ModuÅ‚ do pobierania i analizy danych
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ parser.py
â”‚ â”œâ”€â”€ scraper.py
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ web/ # ModuÅ‚ interfejsu webowego (Flask)
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â””â”€â”€ index.html
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ README.txt
â”‚
â”œâ”€â”€ docker-compose.yml # Plik do uruchamiania kontenerÃ³w
â””â”€â”€ requirements.txt # Wymagania ogÃ³lne



---

## âš™ï¸ Technologie

- **Python 3.10+**
- **BeautifulSoup4** â€“ parsowanie HTML
- **asyncio + multiprocessing** â€“ przetwarzanie wspÃ³Å‚bieÅ¼ne i wieloprocesowe
- **Flask** â€“ interfejs uÅ¼ytkownika
- **MongoDB** â€“ baza danych
- **Docker + Docker Compose** â€“ konteneryzacja i orkiestracja

---

## ğŸ“Œ GÅ‚Ã³wne funkcje

- Pobieranie danych z wielu stron jednoczeÅ›nie
- Profilowanie danych (np. e-maile, adresy, schematy)
- Parsowanie z wykorzystaniem BeautifulSoup
- Zapisywanie danych do MongoDB
- Interfejs webowy do uruchamiania i monitorowania procesÃ³w
- Architektura rozproszona: silnik, web, baza danych jako osobne kontenery

---

ğŸš€ Uruchamianie aplikacji
Upewnij siÄ™, Å¼e Docker i Docker Compose sÄ… zainstalowane i uruchomione.

OtwÃ³rz terminal w gÅ‚Ã³wnym katalogu projektu i wpisz:

bash
Kopiuj
Edytuj
docker-compose up --build -d --remove-orphans
NastÄ™pnie otwÃ³rz przeglÄ…darkÄ™ i wejdÅº na:

arduino
Kopiuj
Edytuj
http://localhost:5000

---
